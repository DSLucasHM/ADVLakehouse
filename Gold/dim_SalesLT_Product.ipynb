{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13914817-0538-4e2d-a6c7-2a4411603144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "dim_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257cc2e2-8ae6-4394-9293-885aef3efadf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Utils/Utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c6900e3-9819-491c-a183-5103502e4d01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    IntegerType, StringType, TimestampType, StructType, StructField\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fdd40b2-4a73-441e-bc7f-69aa38d76fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading Table\n",
    "\n",
    "df = spark.table(\"adlslmcompany_silver.managed_silver.saleslt_product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80970bf9-a8f6-42c4-9816-32c00910376c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Once the data has been cleaned, it should now be adapted to its final requirements, specifically as a dimension Product table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928f9a4e-bb83-47c4-a62b-0e844993519d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Displaying DF\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd031e6a-1bb2-489c-81bd-da77659ffa92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gold_clean_dimproduct(df): \n",
    "\n",
    "    #Drop columns that will not be necessary for this dimension table\n",
    "    df = df.drop(\"rowguid\", \"ModifiedDate\", \"bronze_ingestion_timestamp\", \"silves_transformed_timestamp\" )\n",
    "\n",
    "    # Add processed timestamp column\n",
    "\n",
    "    df = df.withColumn(\"processed_timestamp\", F.current_timestamp())\n",
    "\n",
    "\n",
    "    # Join Product Category Table and select required columns\n",
    "    product_category_df = spark.table(\"adlslmcompany_silver.managed_silver.saleslt_productcategory\")\n",
    "\n",
    "    product_category_df = product_category_df.alias(\"pc1\").join(\n",
    "        product_category_df.alias(\"pc2\"),\n",
    "        F.col(\"pc1.ParentProductCategoryID\") == F.col(\"pc2.ProductCategoryID\"),\n",
    "        \"inner\"\n",
    "    ).select(\n",
    "        F.col(\"pc1.ProductCategoryID\"),\n",
    "        F.col(\"pc1.Name\").alias(\"SubCategory\"),\n",
    "        F.col(\"pc2.Name\").alias(\"Category\")\n",
    "    )\n",
    "\n",
    "    df = df.join(product_category_df, df.ProductCategoryID == product_category_df.ProductCategoryID, \"left\") \\\n",
    "           .select(df[\"*\"], product_category_df[\"Category\"], product_category_df[\"SubCategory\"])\n",
    "\n",
    "       \n",
    "\n",
    "   # Join Product Model Table and select required columns\n",
    "    product_model_df = spark.table(\"adlslmcompany_silver.managed_silver.saleslt_productmodel\")\n",
    "\n",
    "    df = df.join(product_model_df, df.ProductModelID == product_model_df.ProductModelID, \"left\") \\\n",
    "           .select(df[\"*\"], product_model_df[\"Name\"].alias(\"Model\"))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #Cast to ensure datatype and columns\n",
    "    df = df.select(\n",
    "         F.col('ProductID').cast(IntegerType()).alias('ProductID'),\n",
    "         F.col('Name').cast(StringType()).alias('ProductName'),\n",
    "         F.col('Color').cast(StringType()).alias('Color'),\n",
    "         F.col('StandardCost').cast(IntegerType()).alias('StandardCost'),\n",
    "         F.col('ListPrice').cast(IntegerType()).alias('ListPrice'),\n",
    "         F.col('Size').cast(StringType()).alias('Size'),\n",
    "         F.col('Weight').cast(IntegerType()).alias('Weight'),\n",
    "         F.col('Category').cast(StringType()).alias('Category'),\n",
    "         F.col('SubCategory').cast(StringType()).alias('SubCategory'),\n",
    "         F.col('Model').cast(StringType()).alias('Model'),\n",
    "         F.col('processed_timestamp').cast(TimestampType()).alias('processed_timestamp'),\n",
    "         )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1b4a66b-fa4e-4ce8-80fc-0a12dadfe05b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Defining expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"ProductID\", IntegerType(), False),             \n",
    "    StructField(\"ProductName\", StringType(), False),\n",
    "    StructField(\"Color\", StringType(), False),\n",
    "    StructField(\"StandardCost\", IntegerType(), False),\n",
    "    StructField(\"ListPrice\", IntegerType(), False),\n",
    "    StructField(\"Size\", StringType(), False),\n",
    "    StructField(\"Weight\", IntegerType(), False),\n",
    "    StructField(\"Category\", StringType(), False),\n",
    "    StructField(\"SubCategory\", StringType(), False),\n",
    "    StructField(\"Model\", StringType(), False),\n",
    "    StructField(\"processed_timestamp\", TimestampType(), False),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb6cde7-5585-4204-9645-5b5918818298",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transforming DF\n",
    "\n",
    "gold_df = gold_clean_dimproduct(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b458f2a-82c1-4b3c-8e2d-6422c91f40e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Comparing lenghts\n",
    "\n",
    "compare_lengths(df, gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eac57f8-8016-4c48-8794-e39f6174f425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking the schema \n",
    "_validate_schema(gold_df, expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a177039-c0bd-4487-98eb-c32e727ad565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**IMPORTANT: Please note that this is a simulated project; the upsert operation will be executed within this notebook. In a production environment, a dedicated notebook containing only the function and validations would be developed. All function notebooks would be orchestrated by Azure Data Factory (ADF) pipelines or Azure Databricks (ADB) workflows. The method of upsert may vary based on the utilization of auto loader, streaming, or Change Data Feed (CDF).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc00361f-319d-48ca-a490-92ca9d0e8a8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading into the Gold Layer \n",
    "\n",
    "\n",
    "target_table= \"dim_product\"   \n",
    "\n",
    "schema = \"star_schema\"\n",
    "\n",
    "catalog = \"adlscompany_gold\"\n",
    "\n",
    "primary_keys = [\"ProductID\"]\n",
    "\n",
    "\n",
    "upsert_table(gold_df, target_table, primary_keys, schema, catalog )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dim_SalesLT_Product",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
