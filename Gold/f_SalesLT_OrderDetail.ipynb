{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d34ab4ce-2d43-41d7-a1bc-6e3bc3bfb245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "f_OrderDetail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0ba9ed2-922d-414a-bf47-84a67abff9bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**In certain scenarios, it may be possible to create a single Sales table that encompasses all necessary information, rather than maintaining separate Order Header and Order Detail fact tables. However, adopting this approach in the current context would result in the loss of critical data elements such as status and tax. Therefore, this model will consist of two fact tables: Order Header and Order Details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b50fe0d9-c062-4715-8256-ca6fd58ffbd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import DataFrame, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    DecimalType, IntegerType, StringType, TimestampType, StructType, StructField\n",
    ")\n",
    "from pyspark.sql.functions import col, desc, when, datediff, current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07838b26-ac78-4de3-a9b9-3886e9525c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Utils/Utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd325bcd-0880-4b46-8f4d-095d664c6f3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading Table\n",
    "\n",
    "df = spark.table(\"adlslmcompany_silver.managed_silver.sales_orderdetail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354f8257-5b26-4599-8aac-3cb3dec95058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Displaying table\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb478c1a-04b4-4cbe-a6a9-4c49a240ff85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gold_clean_f_orderdetail(df): \n",
    "\n",
    "    #Drop columns that will not be necessary for this dimension table\n",
    "    df = df.drop(\"rowguid\", \"ModifiedDate\", \"bronze_ingestion_timestamp\", \"silves_transformed_timestamp\" )\n",
    "\n",
    "    # Adds processed timestamp\n",
    "    df = df.withColumn(\"processed_timestamp\", F.current_timestamp())\n",
    "\n",
    "    #Cast to ensure datatype\n",
    "    df = df.select(\n",
    "         F.col('SalesOrderID').cast(IntegerType()).alias('SalesOrderID'),\n",
    "         F.col('SalesOrderDetailID').cast(IntegerType()).alias('SalesOrderDetailID'),\n",
    "         F.col('OrderQty').cast(IntegerType()).alias('OrderQty'),\n",
    "         F.col('ProductID').cast(IntegerType()).alias('ProductID'),\n",
    "         F.col('UnitPrice').cast(DecimalType(19,4)).alias('UnitPrice'),\n",
    "         F.col('UnitPriceDiscount').cast(DecimalType(19,4)).alias('UnitPriceDiscount'),\n",
    "         F.col('LineTotal').cast(DecimalType(38,6)).alias('LineTotal'),\n",
    "         F.col('processed_timestamp').cast(TimestampType()).alias('processed_timestamp')\n",
    "                 )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3d34c6a-df88-4822-8a68-35e4a23d024b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Defining expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"SalesOrderID\", IntegerType(), False),             \n",
    "    StructField(\"SalesOrderDetailID\", IntegerType(), False),\n",
    "    StructField(\"OrderQty\", IntegerType(), False),\n",
    "    StructField(\"ProductID\", IntegerType(), False),\n",
    "    StructField(\"UnitPrice\", DecimalType(19,4), False),\n",
    "    StructField(\"UnitPriceDiscount\", DecimalType(19,4), False),\n",
    "    StructField(\"LineTotal\", DecimalType(38,6), False),\n",
    "    StructField(\"processed_timestamp\", TimestampType(), False),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea423cb8-c1f4-468c-80f1-6dc159240ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transforming DF\n",
    "\n",
    "gold_df = gold_clean_f_orderdetail(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e1cfc3f-034e-49b5-ad64-1d01e252c5c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Comparing lenghts\n",
    "\n",
    "compare_lengths(df, gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66725412-058f-4c13-b287-da978a6ac07d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking the schema \n",
    "_validate_schema(gold_df, expected_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "462d32dd-9e9c-4153-a607-1bdf397379d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**IMPORTANT: Please note that this is a simulated project; the upsert operation will be executed within this notebook. In a production environment, a dedicated notebook containing only the function and validations would be developed. All function notebooks would be orchestrated by Azure Data Factory (ADF) pipelines or Azure Databricks (ADB) workflows. The method of upsert may vary based on the utilization of auto loader, streaming, or Change Data Feed (CDF).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9032bd45-d7d7-427a-bff6-eda7c69929ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading into the Gold Layer \n",
    "# \n",
    "#  \n",
    "target_table= \"f_orderdetail\"   \n",
    "\n",
    "schema = \"star_schema\"\n",
    "\n",
    "catalog = \"adlscompany_gold\"\n",
    "\n",
    "primary_keys = [\"SalesOrderDetailID\"]\n",
    "\n",
    "\n",
    "upsert_table(gold_df, target_table, primary_keys, schema, catalog )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "f_SalesLT_OrderDetail",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
