{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f4dc96d-8034-4774-9595-0bcade138081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "SalesLT_Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec694c62-3148-4cc4-a77f-a2c7cda0a158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable auto merge\n",
    "\n",
    "spark.sql(\"SET spark.databricks.delta.schema.autoMerge.enabled = true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d85f12-fcdb-4703-8a95-85edea42ee8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    DecimalType, IntegerType, StringType, TimestampType, StructType, StructField\n",
    ")\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.sql.functions import count, desc\n",
    "from pyspark.sql.functions import col, when, datediff, current_date\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b42fad10-f319-4c22-b1ef-9116a8f2b8a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Utils/Utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da67310b-d327-468b-8acc-d1fb583e69b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading Table\n",
    "\n",
    "df = spark.table(\"adlslmcompany_bronze.managed_bronze.saleslt_product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455c97a9-96ba-4de7-ab3c-8659fc932c50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Displaying table\n",
    "\n",
    "df.limit(10).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "798d49e3-7c3a-4d02-83fe-4438b93638a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking for duplicated ID's\n",
    "\n",
    "checkduplicates(df, \"ProductID\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e50c71d4-a6f1-4434-8649-2bb89a46d13c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking for duplicated product names\n",
    "\n",
    "checkduplicates(df, \"Name\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ec407d-b331-41a2-8094-f519151bc154",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This section identifies duplicated values in the DataFrame for further analysis.\n",
    "\n",
    "name_counts = df.groupBy(\"Name\").count().filter(\"count > 1\")\n",
    "\n",
    "# The original DataFrame is joined with the filtered counts DataFrame to isolate duplicated entries.\n",
    "df_duplicates = df.join(name_counts, on=\"Name\", how=\"inner\").select(df[\"*\"])\n",
    "\n",
    "# The duplicated entries are ordered by name for better visibility.\n",
    "df_duplicates.orderBy(\"Name\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fa5454-1b61-48bd-a1a3-b52a3dc1a8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Once this dataset contains only 68 rows, it is possible to manually verify the values. However, in scenarios with larger datasets, a function to check all columns should be utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6b75f6-643f-4265-946e-e4e4ed4fb5e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Based on the analysis, it is evident that all the rows are duplicated without any value changes. Therefore, the rows can be dropped.\n",
    "\n",
    "df = deduplicate(df, \"Name\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6ca0b40-1b96-45d3-ac6c-89cb11e70ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def silver_clean_salesproduct(df): \n",
    "\n",
    "    #Deleting ireelevant columns\n",
    "    df = df.drop(\"ThumbNailPhoto\", \"ThumbnailPhotoFileName\", \"ProductNumber\")\n",
    "   \n",
    "\n",
    "    \n",
    "        # Creating a selling time column based on the SellStart and SellEndDate\n",
    "    df = df.withColumn(\n",
    "        \"SalesTime\", \n",
    "        when(\n",
    "            col(\"SellEndDate\").isNull(), \n",
    "            datediff(current_date(), col(\"sellStartDate\"))\n",
    "        ).otherwise(\n",
    "            datediff(col(\"SellEndDate\"), col(\"sellStartDate\"))\n",
    "        ).cast(IntegerType())\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Deduplicating\n",
    "    df= deduplicate(df, \"Name\", None)\n",
    "    \n",
    "\n",
    "    # Adds transformation Date column\n",
    "    df = df.withColumn(\"silves_transformed_timestamp\", F.current_timestamp())\n",
    "    \n",
    "\n",
    "    #Cast to ensure datatype\n",
    "    df = df.select(\n",
    "         F.col('ProductID').cast(IntegerType()).alias('ProductID'),\n",
    "         F.col('Name').cast(StringType()).alias('Name'), \n",
    "         F.col('Color').cast(StringType()).alias('Color'),\n",
    "         F.col('ProductModelID').cast(StringType()).alias('ProductModelID'),\n",
    "         F.col('StandardCost').cast(DecimalType(19,2)).alias('StandardCost'),\n",
    "         F.col('ListPrice').cast(DecimalType(19,2)).alias('ListPrice'),\n",
    "         F.col('Size').cast(StringType()).alias('Size'),\n",
    "         F.col('Weight').cast(DecimalType(8,2)).alias('Weight'),\n",
    "         F.col('ProductCategoryID').cast(IntegerType()).alias('ProductCategoryID'),\n",
    "         F.col('SellStartDate').cast(TimestampType()).alias('SellStartDate'),\n",
    "         F.col('SellEndDate').cast(TimestampType()).alias('SellEndDate'),\n",
    "         F.col('DiscontinuedDate').cast(TimestampType()).alias('DiscontinuedDate'),\n",
    "         F.col('rowguid').cast(StringType()).alias('rowguid'),\n",
    "         F.col('ModifiedDate').cast(TimestampType()).alias('ModifiedDate'),\n",
    "         F.col('bronze_ingestion_timestamp').cast(TimestampType()).alias('bronze_ingestion_timestamp'),\n",
    "         F.col('silves_transformed_timestamp').cast(TimestampType()).alias('silves_transformed_timestamp'),\n",
    "                 )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9761cdc8-84e6-4e91-88ff-5112f4bec28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Defining expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"ProductID\", IntegerType(), False),             \n",
    "    StructField(\"Name\", StringType(), True),                  \n",
    "    StructField(\"Color\", StringType(), True),\n",
    "    StructField(\"ProductModelID\", StringType(), True),\n",
    "    StructField(\"StandardCost\", DecimalType(19,2), True),\n",
    "    StructField(\"ListPrice\", DecimalType(19,2), False),  \n",
    "    StructField(\"Size\", StringType(), False),\n",
    "    StructField(\"Weight\", DecimalType(8,2), False),\n",
    "    StructField(\"ProductCategoryID\", IntegerType(), False),\n",
    "    StructField(\"SellStartDate\", TimestampType(), False),\n",
    "    StructField(\"SellEndDate\", TimestampType(), False),\n",
    "    StructField(\"DiscontinuedDate\", TimestampType(), False),\n",
    "    StructField(\"rowguid\", StringType(), False),\n",
    "    StructField(\"ModifiedDate\", TimestampType(), False) ,\n",
    "    StructField(\"bronze_ingestion_timestamp\", TimestampType(), False),\n",
    "    StructField(\"silves_transformed_timestamp\", TimestampType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf9e11b-c956-4fd2-ae15-217b876aa738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df = silver_clean_salesproduct(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e0d848c-067e-4332-895e-31b9215867b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking for duplicated product names\n",
    "\n",
    "checkduplicates(silver_df, \"Name\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b998ce56-d3fc-499e-bb9d-54cd3bb49358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking the schema \n",
    "_validate_schema(silver_df, expected_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b49a6eae-ff14-4d26-94e0-a7c3a6aa5ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Comparing lenghts\n",
    "\n",
    "compare_lengths(df, silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f7d60f-9af0-4609-acd9-b38b446eab46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**IMPORTANT: Please note that this is a simulated project; the upsert operation will be executed within this notebook. In a production environment, a dedicated notebook containing only the function and validations would be developed. All function notebooks would be orchestrated by Azure Data Factory (ADF) pipelines or Azure Databricks (ADB) workflows. The method of upsert may vary based on the utilization of auto loader, streaming, or Change Data Feed (CDF).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43232afe-ef44-4099-b40f-a0cf80e779d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " #Loading into the Silver Layer   \n",
    "\n",
    "target_table= \"saleslt_product\"   \n",
    "\n",
    "schema = \"managed_silver\"\n",
    "\n",
    "catalog = \"adlslmcompany_silver\"\n",
    "\n",
    "primary_keys = [\"ProductID\"]\n",
    "\n",
    "\n",
    "_upsert_silver_table(silver_df, target_table, primary_keys, schema, catalog )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Saleslt_Product",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
